{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fcb3395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1505d668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CONFIGURATION =====\n",
    "DATASET_ROOT = \"G:/Project/DeepFake_Video_Detection/Dataset\"  # folder containing 'original/', 'Deepfakes/', etc.\n",
    "ALPHA_DATASET_ROOT = \"G:/Project/DeepFake_Video_Detection/Dataset/Alpha_Dataset\"  # folder containing 'original/', 'Deepfakes/', etc.\n",
    "CSV_FOLDER = os.path.join(ALPHA_DATASET_ROOT, \"csv\")  # folder containing the CSV metadata\n",
    "TEST_SIZE = 0.15\n",
    "VAL_SIZE = 0.15\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90cf135e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total videos listed in CSVs: 1750\n",
      "   Unnamed: 0              file_path label  \\\n",
      "0           6  Deepfakes/006_002.mp4  FAKE   \n",
      "1          22  Deepfakes/022_489.mp4  FAKE   \n",
      "2          27  Deepfakes/027_009.mp4  FAKE   \n",
      "3          30  Deepfakes/030_193.mp4  FAKE   \n",
      "4          32  Deepfakes/032_944.mp4  FAKE   \n",
      "\n",
      "                                            abs_path  \n",
      "0  G:/Project/DeepFake_Video_Detection/Dataset/Al...  \n",
      "1  G:/Project/DeepFake_Video_Detection/Dataset/Al...  \n",
      "2  G:/Project/DeepFake_Video_Detection/Dataset/Al...  \n",
      "3  G:/Project/DeepFake_Video_Detection/Dataset/Al...  \n",
      "4  G:/Project/DeepFake_Video_Detection/Dataset/Al...  \n"
     ]
    }
   ],
   "source": [
    "# ===== LOAD ALL CSVs =====\n",
    "csv_files = glob.glob(os.path.join(CSV_FOLDER, \"*.csv\"))\n",
    "all_dfs = []\n",
    "\n",
    "for csv_path in csv_files:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    # Ensure column names are standardized\n",
    "    df = df.rename(columns={\"File Path\": \"file_path\", \"Label\": \"label\"})\n",
    "    # Create absolute paths\n",
    "    df[\"abs_path\"] = df[\"file_path\"].apply(lambda x: os.path.join(ALPHA_DATASET_ROOT, x))\n",
    "    all_dfs.append(df)\n",
    "\n",
    "# Merge into a single DataFrame\n",
    "full_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "print(f\"Total videos listed in CSVs: {len(full_df)}\")\n",
    "print(full_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6dd8997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All files exist.\n"
     ]
    }
   ],
   "source": [
    "# ===== VERIFY FILES EXIST =====\n",
    "missing_files = [p for p in full_df[\"abs_path\"] if not os.path.exists(p)]\n",
    "if missing_files:\n",
    "    print(f\"[WARNING] Missing {len(missing_files)} files:\")\n",
    "    for mf in missing_files:\n",
    "        print(mf)\n",
    "else:\n",
    "    print(\"✅ All files exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b618b1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class distribution:\n",
      "label\n",
      "REAL    1000\n",
      "FAKE     750\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ===== SUMMARIZE CLASS DISTRIBUTION =====\n",
    "print(\"\\nClass distribution:\")\n",
    "print(full_df[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d9ffff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== STRATIFIED SPLIT =====\n",
    "# First split: train+val vs test\n",
    "train_val_df, test_df = train_test_split(\n",
    "    full_df,\n",
    "    test_size=TEST_SIZE,\n",
    "    stratify=full_df[\"label\"],\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "# Second split: train vs val\n",
    "val_relative_size = VAL_SIZE / (1 - TEST_SIZE)\n",
    "train_df, val_df = train_test_split(\n",
    "    train_val_df,\n",
    "    test_size=val_relative_size,\n",
    "    stratify=train_val_df[\"label\"],\n",
    "    random_state=RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ef977b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 1224 samples | {'REAL': 700, 'FAKE': 524}\n",
      "Validation set: 263 samples | {'REAL': 150, 'FAKE': 113}\n",
      "Test set: 263 samples | {'REAL': 150, 'FAKE': 113}\n"
     ]
    }
   ],
   "source": [
    "# ===== PRINT COUNTS =====\n",
    "def summarize_split(name, df):\n",
    "    counts = df[\"label\"].value_counts().to_dict()\n",
    "    print(f\"{name} set: {len(df)} samples | {counts}\")\n",
    "\n",
    "summarize_split(\"Train\", train_df)\n",
    "summarize_split(\"Validation\", val_df)\n",
    "summarize_split(\"Test\", test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa161df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Train entries:\n",
      "      Unnamed: 0              file_path label  \\\n",
      "1097         347       original/347.mp4  REAL   \n",
      "942          192       original/192.mp4  REAL   \n",
      "1216         466       original/466.mp4  REAL   \n",
      "239          595  Face2Face/595_597.mp4  FAKE   \n",
      "787           37       original/037.mp4  REAL   \n",
      "\n",
      "                                               abs_path  \n",
      "1097  G:/Project/DeepFake_Video_Detection/Dataset/Al...  \n",
      "942   G:/Project/DeepFake_Video_Detection/Dataset/Al...  \n",
      "1216  G:/Project/DeepFake_Video_Detection/Dataset/Al...  \n",
      "239   G:/Project/DeepFake_Video_Detection/Dataset/Al...  \n",
      "787   G:/Project/DeepFake_Video_Detection/Dataset/Al...  \n",
      "\n",
      "Sample Validation entries:\n",
      "      Unnamed: 0                file_path label  \\\n",
      "1730         980         original/980.mp4  REAL   \n",
      "386          597  FaceShifter/597_595.mp4  FAKE   \n",
      "1059         309         original/309.mp4  REAL   \n",
      "831           81         original/081.mp4  REAL   \n",
      "1545         795         original/795.mp4  REAL   \n",
      "\n",
      "                                               abs_path  \n",
      "1730  G:/Project/DeepFake_Video_Detection/Dataset/Al...  \n",
      "386   G:/Project/DeepFake_Video_Detection/Dataset/Al...  \n",
      "1059  G:/Project/DeepFake_Video_Detection/Dataset/Al...  \n",
      "831   G:/Project/DeepFake_Video_Detection/Dataset/Al...  \n",
      "1545  G:/Project/DeepFake_Video_Detection/Dataset/Al...  \n",
      "\n",
      "Sample Test entries:\n",
      "      Unnamed: 0              file_path label  \\\n",
      "160           91  Face2Face/091_116.mp4  FAKE   \n",
      "956          206       original/206.mp4  REAL   \n",
      "1416         666       original/666.mp4  REAL   \n",
      "1747         997       original/997.mp4  REAL   \n",
      "58           441  Deepfakes/441_439.mp4  FAKE   \n",
      "\n",
      "                                               abs_path  \n",
      "160   G:/Project/DeepFake_Video_Detection/Dataset/Al...  \n",
      "956   G:/Project/DeepFake_Video_Detection/Dataset/Al...  \n",
      "1416  G:/Project/DeepFake_Video_Detection/Dataset/Al...  \n",
      "1747  G:/Project/DeepFake_Video_Detection/Dataset/Al...  \n",
      "58    G:/Project/DeepFake_Video_Detection/Dataset/Al...  \n"
     ]
    }
   ],
   "source": [
    "# ===== PREVIEW SAMPLES =====\n",
    "print(\"\\nSample Train entries:\")\n",
    "print(train_df.sample(5, random_state=RANDOM_SEED))\n",
    "\n",
    "print(\"\\nSample Validation entries:\")\n",
    "print(val_df.sample(5, random_state=RANDOM_SEED))\n",
    "\n",
    "print(\"\\nSample Test entries:\")\n",
    "print(test_df.sample(5, random_state=RANDOM_SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb35c60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Stage 1 completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# ===== OPTIONAL: Save splits to CSV =====\n",
    "train_df.to_csv(os.path.join(DATASET_ROOT, \"train_split.csv\"), index=False)\n",
    "val_df.to_csv(os.path.join(DATASET_ROOT, \"val_split.csv\"), index=False)\n",
    "test_df.to_csv(os.path.join(DATASET_ROOT, \"test_split.csv\"), index=False)\n",
    "\n",
    "print(\"\\n✅ Stage 1 completed successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
